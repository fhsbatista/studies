# Patterns
Ao trabalhar com microsserviços temos problemas que não existem nos sistemas monolíticos. Para lidar com esses problemas, existem diversos padrões.

## Api Composition
Exemplo de problema:
 - contexto: Geração de relátorios
 - Um frontend, Serviço A e serviço B
 - Pra gerar o relatório
    - frontend chama serviço A
    - chama o serviço B
    - junta os dados e gera o relatório

![](images/patterns/frontend-reports.png)

Nesse exemplo, nosso problema tá resolvido.

Mas e se em vez de um frontend, temos um outro service como client que chama os outros serviços, junta os dados e gera o relatório?

![](images/patterns/service-reports.png)

Nos dois casos acima, temos exemplos de API Composition (composer), pois temos um componente (o frontend ou o serviço no segundo exemplo) que são responsáveis por chamar os outros serviços, juntar os dados e gerar o relatório.

De maneira mais elaborada, esse padrão é quando nós fazemos com que os clientes do serviços sejam responsáveis por chamar os serviços na ordem correta e combinar os dados gerados por eles. É o padrão mais simples que temos e um dos mais importantes.

### Vantagens
Fica centralizado em um único lugar a responsabilidade de buscar e combinar os dados, e os serviços não precisam lidar com isso, não criando acoplamento entre eles.

### Desvantagens
 - Problema de disponibilidade: Se um dos serviços cair, o composer basicamente cai também.
 - Consistência nos dados: pode ser que ao terminar de chamar todos os serviços, os dados gerador pelos primeiros serviços já estejam desatualizados.
 - Aumento de complexidade pois adicionamos um componente somente pra compor esses dados.
 - Temos um serviço criado com o objeto só de chamar outros serviços.
 - Alta latência pois por baixo dos panos vários serviços estão sendo chamados.

### Resiliência
Como o composer vai fazer operações ou gerar dados a partir de outros services, é precisa pensar no que fazer caso algum deles falhe ou esteja indisponível.
Num relatório, por exemplo, temos a opção de colocar as informações referentes a um serviço que falou de maneira reduzida.

## Decompose by business capability
Esse é um padrão que vai ajudar a iniciar migração de um monolito para uma distrubuir em microsserviços.

### Exemplo prático
Um sistema monolítico com áreas de:
 - Financeiro
 - CRM
 - Compras
 - Clientes

Um monolito desse tipo, poderíamos inicialmente gerar um serviço para cada uma dessas áreas.
O grande dificultadr, é que normalmente, a relação entre áreas do monilitos e microsserviços não serão 1 : 1.

Por exemplo, o módulo financeiro pode ter ligações com a área de clientes e CRM, gerando áreas cinzentas. Esses casos que vão gerar mais dificuldade na separação.

Uma maneira de diminuir essas áreas cinzentas é usando o DDD.

### DDD
Com ele, vamos conseguir elencar o que faz parte do **core**  e os **subdomínios** do sistema, assim deixando mais claro como dividir os microsserviços.

### Resumo
Um dos principais pontos é entender que, embora o monolito já esteja separado em contextos, módulos etc, essas separações dificilmente vão funcionar como microsserviços. Existem intersecções entre esses módulos que precisam ser entendidas pra conseguir fazer a decomposição.

## Strangler application
Esse é um padrao que pode ser usado na transição de monolito para microsserviços.

Com ele, vamos definir algumas regras para novas features no sistema.

1 - Toda nova feature será feita como microsserviço
2 - Pegar pequenos pedaços do sistema monolítico e transformar em microsserviço.

Dessa forma, vamos diminuindo o monolito aos poucos, e com o passar do tempo, o monolito não estará mais fazendo nada, por isso o nome "strangler", é como se estivéssemos estrangulando o monolito aos poucos até que ele morra.

### Pontos de atenção
#### Comunicação
Um dos primeiros problemas que irá surgir é a comunicação com o monolito. Pra isso provavelmente será necessário colocar novas ferramentas, como para eventos por exemplo, que ainda não são usadas, aumento o atrito para começar essa migração.

#### Maturidade da equipe
É necessário que a equipe já esteja preparada para coisas como automação, cobertura de testes etc. Sem essas coisas é inviável trabalhar com microsserviços, e então, relembrando coisas anotadas anteriormente, se a equipe não possui essa maturidade, trabalhar com microsserviços não é uma opção.

#### Banco de dados
A ideia é que cada microsserviço tenha seu próprio banco de dados. Mas para esse momento de transição, é comum que se use um banco compartilhado para esses serviços e isso vai sendo migrado para o banco específico do serviço.

Para auxiliar nessa migração, o que se pode fazer é migrar para o novo banco do serviço somente os dados que ele realmente usa.

O uso de APM também pode ajudar com as métricas que mostram o uso do banco, quais tabelas sao mais lidas, quais tem mais escrita etc. Isso pode dar insights de como fazer a migração.

#### APM
O correto é que cada serviço tenha seu próprio APM. Isso é obrigatório pra conseguir acomapanhar a saúde do serviço.

#### Métricas
É interessante definir métricas esperadas para os novos serviços e configurar alarmes, para garantir que anormalidades serão mitigadas o quanto antes.

## ACL (anti corruption layer)
É um padrão onde criamos um serviço para traduzir inputs e outputs de um serviço para outro, a fim de que o input/output de um serviço B não polua o serviço A.

### Migração monolito pra microsserviços
Isso é útil por exemplo na fase de migração de monolito para microsserviços. Durante a migração, nosso microsserviço pode passar a usar novos campos, nomes, estruturas de dados que não compatíveis com a forma com que a mesma feature usava no monolito.

E como durante essa fase de transição, é comum que o monolito se comunique com o microsserviço (ou vice versa), o código antigo do monolito pode acabar poluindo o microsserviço com coisas como:

 - O monolito pede um campo novo para processar um pagamento, mas é um campo obsoleto e por isso o microsserviço não o considera. Mas o campo é obrigatório.

Nesse exemplo, o ACL pode intermediar o microsserviço e o monolito para absorver esses detalhes, não poluindo o microsserviço com esses detalhes que, para o contexto do microsserviço são inúteis.

### Ser agnósticos a parceiros
Isso também pode ser usado quando queremos que detalhes das APIs de parceiras interfiram em em como vamos construir nossos serviços. Isso é útil para que nosso código não siga o contexto do parceiro, e também para ser agnóstico a eles, assim podendo ter vários parceiros e trocar entre eles de maneira transparente.

Por exemplo, no caso de parceiros de gateway de pagamentos ou baas.

Podemos achar interessante, que nosos microsserviço de pagamento possa alternar entre parceiros de gateway, e pra isso vamos implementar um pra cada bandeira de cartão, e deve ser usado aquele com a menor taxa para o cartão que o usuário vai usar.

Uma forma de fazer isso, é inserindo a lógica de cada um desses gateways no nosso microsserviço, mas isso vai acabar "corrompendo", "poluindo" ele.

O microsserviço estaria acoplado a cada um desses gateways, e portanto sendo afetado quando a interface pública desses mudarem.

Para evitar isso, criamos um ACL pra intermediar nosso microsserviço e os gateways.

Assim, o nosso microsserviço chama o ACL, que vai ter uma interface pública uniforme. Para o microsserviço, o ACL é o próprio gateway. Por baixo dos panos ele está funcionando como uma espécie de proxy.

Esse ACL, internamente, vai receber o pedido de pagamento e direcionar pro gateway correto seguindo as regras necessárias e também cuidando do input/output compatível com cada um deles.

![](images/patterns/acl.png)

## API Gateway
É um ponto único de entrada para um conjunto de microsserviços. Ele é útil pois abstrai os servidores para os clientes, sendo assim, um tipo de "proxy reverso".

### Providers
Temos o Kong que é bastante popular e pode ser usado em conjunto com kubernetes.
Todos os cloud providers (aws, gcp etc) também fornecem essa ferramenta.

### Utilidades

#### Facilitação de acesso aos servidores
Como os microsserviços estão em uma rede, cada um tem IP e DNS. E esses também podem estar espalhados em máquinas e pods diferentes.

Ou seja, o acesso aos microsserviços não é trivial. Para facilitar isso, usamos um API Gateway que abstrai o acesso aos serviços para os clientes deles.

Assim, os clientes chamam o API Gateway, e esse trata de redirecionar a chamada pro lugar certo.

#### Rate limiting
Se os microsserviços estivessem expostos para a internet, seriam vulneráveis à DDoS. Pra evitar isso precisamos de rate limiting.

O API gateway facilita essa configuração.

*Além de prevenir DDoS, isso pode ser útil para dar preferência de rate limiting para clientes.

#### Modificação de payload
O API gateway pode ser usado para transformar o payload antes de repassar pro serviço. Por exemplo, transformar um json pra um xml.

#### Autenticação
Podmeos centralizar a autenticação no API Gateway, assim não precisamos replicar autenticação em cada um dos serviços.

O keycloak é muito usado em conjunto com o API Gateway pra isso.

Assim, o API Gateway repassa a chamada pro serviço já com o id do usuário autenticado, e o serviço na precisa verificar se tá autenticado.

#### Agrupamento dos serviços
Pode ser usado pra agrupar os serviços por contexto, mitigando o "estrela da morte", pois simplifica as chamdas pois os microsserviços podem fazer elas direcionadas para um "contexto" em vez do microsserviço diretamente.

ex: microsserviço de checkout de pagamento pode chamar o de "delivery" que é mais genérico em vez de chamar de "impressão de etiqueta xyz".

### Stateful vs Stateless
O API Gateway podem manter estado ou não.
Quando tem estado, é usado um banco de dados para manter os dados que serão necessários.

Caso não, entao sendo stateless, temos um manifesto com as configurações que devem regir o comportamento do gateway.

## BFF (backend for frontend)
Num cenário onde temos mais de um client frontend, como tv, desktop, web e mobile, podemos ter um problema se todos esses acessarem o mesmo API Gateway ou até mesmo os serviços diretamente.

Isso pode trazer alguns problemas, pois os dados que cada um desses frontends precisam são diferentes, as vezes muito diferentes. As vezes tem jornadas diferentes também. Por exemplo, tv normalmente não tem cadastro, um app mobile recebe bem menos dados pra evitar lentidão e consumo de pacote de dados.

Pra mitigir isso, um pattern bem comum acaba surgindo que é o BFF. Que nada mais é do que um backend específico pra cada frontend. Esse backend fica responsável por adaptar a comunicaçao do sistema de microsserviços para cada tipo de client, com endpoints que se adequam mais a necessidade de cada um deles.

Isso melhora a vida tanto do frontend quanto dos serviços, pois esse intermediário faz com que o frontend lide com uma API de interface pública mais amigáve, e evita que os serviços precisem ser alterados para se ajustar a eventuais mudanças motivadas pelo tipo do frontend (ex: por if em algum fluxo pra adaptar o que acontece se o client for app ios ou android, tv etc).

### Graphql como alternativa
A flexibilidade do graphql pode substituir o bff, mas é necessário ponderar bem pois o graphql também adiciona muita complexidade, então não necessariamente é mais "simples" do que implementar BFFs.

## Banco de dados
Aqui existe uma polêmica.
Sempre se é recomendado, e com vários argumentos, que cada microsserviço tenha seu próprio banco. Isso facilitaria a divisão do trabalho entre equipes, sem que uma impacte o trabalho da outra, e também permite escalibalidade horizontal independente entre eles.

Por outro lado, ter os dados dos serviços no mesmo banco, facilita pois evita várias "voltas" que temos que fazer em um fluxo, pois as vezes um serviço pode chamar o outro somente para pegar dados, e isso é feito de maneira assíncrona, ou seja, uma baixa complexidade só para pegar alguns dados. Logo, ter isso já disponível no banco de dados facilitaria muito, mas isso vem com o custo dos problemas citados no parágrafo acima.

Enfim, particularmente acredito que, se foi decidido usar microsserviços, também foi decidido arcar com o preço disso que é ter bancos independentes. As vantagens em se trabalhar com microsserviços vem justamente dessa independência, então compartilhar um banco talvez comece a gerar o cenário de "monolito distribuído", o que é o pior dos mundos, pois temos as desvantagens de monolito e dos microsserviços, sem ter as vantagens deles.

Acredito que seja aceitável o compartilhamento de banco somente no momento de transição do monolito para os microsserviços, que é um momento em que a equipe ainda está descobrindo, experimentando, qual será a divisão ideal dos serviços.

Obs: uma estratégia para evitar as "voltas" num fluxo só pra consultar dados em outros serviços, é ter a cópia dos dados necessários em cada microsserviço, usando a ideia de event sourcing e consistência eventual.

## Relatórios e consolidação de informações
Dado a natureza distrubuída da arquitetura de microsserviços, quando precisamos gerar relatórios ou consolidar informações pra outros fins, não é nada fácil pois precisamos pegar os dados de vários lugares diferentes.

E além de não ser fácil, vai ser lento já que várias chamadas assíncronas serão feitas.

### Opções
#### Microsserviço pra gerar o relatório em background
Essa é uma solução muito comum. Por exemplo, em muitos apps de conta digital, o extrato é enviado por email.

Isso permite que o usuário não fique esperando o relatório de maneira imediata, com um loading na tela por exemplo, o que também aumentaria o tempo de reposta da aplicação podendo gerar problemas, mas também permite que se escolha quando o relatório será gerado (não necessariamente ele precisa ser gerado de maneira imediata) e então dando a opção de gerá-lo em um momento que exista mais recursos de hardware disponíveis.

#### Microsserviço exclusivo pro relatório
Esse microsserviço ficaria a todo momento buscando atualizações nos dados. Assim, quando o relatório for solicitado, esse microsserviço já tem as informações prontas.

#### Tabelas de projeção
Essa é uma opção que pode ser implementada num microsserviço específico pro relatório ou num outro microsserviço mais genérico.

A ideia é ter uma tabela específica pro relatório, onde cada coluna seria uma informação do relatório.

Essa tabela, seria atualizada por "triggers". Assim, o microsserviço responsável por essa tabela pode ficar ouvindo os tópicos do kafka que recebem mensagens de atualização desses dados, e vai atualizando essa tabela conforme recebe esses eventos.

Por exemplo, quando é publicada uma mensagem de alteração do nome, o microsserviço com essa tabela recebe a mensagem e atualizada a tabela.

Depois, uma nova transação é feita, e esse microsserviço recebe a mensagem e atualiza o saldo e etc.

Uma outra opção pra atualizar a tabela, é em vez do microsserviço ficar escutando um tópico pra saber quando atualizar, ele na verdade ser chamado pelo microsserviço responsável pela alteração, e quando chamado ele atualizada a tabela.

## Transactional outbox
Esse é um padrão que evita a perda de dados causada por mensagens que um broker não conseguiu confirmar.
Isso pode acontecer se o broker sair do ar por exemplo.

Essa é uma situação que precisa de planos de contingência pois mensagens perdidas podem ser catástroficas dependendo do contexto, como mensagens de transações financeiras por exemplo.

Para contornar isso, podemos adotar o pattern "transactional outbox". É uma estratégia bem simples. A ideia é, antes de um serviço enviar uma mensagem, ele salva os dados em uma tabela. Então o serviço envia a mensagem, e somente quando o broker confirmar o ACK (que pode ser dos niveis ACK 1, ACK -1 ou ACK ALL), o primeiro serviço pode tirar os dados da tabela.

Ou seja, os dados nunca serão perdidos. Caso o broker saia do ar, ele vai ter tempo de voltar ao ar, e no tempo dele voltar a processar os eventos e pronto, nenhum dado foi perdido.

Obs: Essa estratégia não necessariamente se refere somente a comunicação com brokers de mensageria. Pode ser usado pra qualquer comunicação em que precisamos garantir que dados não serão perdidos. Então podemos usar pra requisições http, grpc etc.

### Bancos de dados recomendados
Para não misturar esses dados temporários com o restante dos dados, podemos usar alguns bancos específicos.

 - Redis salvando os dados em disco em vez de memória
 - Key values com o dynamodb.
 - Ou usar o mesmo banco, mas em um schema diferente.

É bem interessante salvar esses dados de maneira separada, pra evitar confusão já que o propósito desses dados é realmente apenas para resolver um eventual problema do broker estar fora.

### Design patterns
É interessante existir um SDK interno da empresa pra já abstrair essa lógica e evitar erros dos devs tendo que implementar isso a todo momento.

Por exemplo, podemos ter um sdk de envio de mensagens pro broker, que por baixo dos panos já salva esses dados na tabela temporária.

## Secret manager
Um dos problemas causados pela quantidade grande de microsserviços é como gerenciar as credenciais de todos eles. Por conta da quantidade, pode ser inviável gerenciar eles manualmente.

Pra isso, temos as ferramentas "secret manager".

Exemplos de ferramentas:
 - AWS -> Secret manager
 - Hashcorp -> Vault

Essas ferramentas basicamente armazenam suas credenciais de maneira criptografada com auxílio de um "KMS".
Assim, essas credenciais não precisam ficar num .env, variável de ambiente etc, que são opções menos seguras que uma ferramenta como um secret manager

### Rotacionamento de chaves
Essas ferramentas são muito úteis também para rotacionar chaves de maneira mais fácil. Com essas ferramentas, já conseguimos fazer esse rotacionamento por meio de lambda functions.
O secret manager, ao entender que precisa rotacionar, chama a function e já rotaciona a chave. Dessa forma, o rotacionamento já pode acontecer de forma automática.

## Padronização de logs
Obs: altamente relacionado com observabilidade.

Como agora a aplicação está distribuída, as vezes em VMs diferentes, containers diferentes, linguagens/frameworks diferentes, precisamos cuidar para não perder os logs, pois por exemplo, dependendo da infra, a máquina em que uma requisição aconteceu e deu erro já pode ter sido derrubada quando formos investigar o problema. Teremos também o log espalhado em vários lugares diferentes (exemplo koin em que eu precisava olhar o log de cada container pra ver se eu achava o que precisava) etc.

Além disso, como agora uma chamada pode ir gerando chamadas em vários outros serviços, fica difícil a gente saber onde procurar algo.

E temos outro problema também. Como cada serviço é independente, os logs que cada um gera não necessariamente estarão no mesmo "formato", pois podem estar em linguagem/framework diferentes, são mantidos por equipes com necessidades diferentes etc.

Pra resolver isso, precisamos padronizar os logs de todos os serviços, usando um SDK de logs, que todas as equipes devem usar para fazer os logs. Assim, os logs saem sempre no mesmo formato.

### Cuidados com stacktrace
Algumas ferramentas podem ter uma quebra de linha pra cada chamada que estava no stacktrace. Então precisamos garantir que nosso sistema de logs vai conseguir identificar o início e o final do stacktrace corretamente.

### Ferramentas que ajudam na padronização
Essas já estão preparadas para padronizar os logs de diversas ferramentas, frameworks e linguagens, assim não precisamos fazer esse tratamento manualmente.

- Logstash
- Filebit
