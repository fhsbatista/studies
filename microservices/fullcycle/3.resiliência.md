# Resiliência
Esse é um tema muito importante em arquitetura de microsserviços.

Precisamos ter a seguinte premissa:
"Todo serviço, eventualmente vai falhar".

Por conta disso, precisamos ter planos para mitigar essas falhas de maneira a afetar o sistema todo o mínimo possível.

O que é resiliência:
> É a capacidade de se adaptar ao ambiente em vez de quebrar.

Queremos tomar iniciativas deliberadas, intencionais, de mapear os pontos de falhas do sistema e maneiras de mitigar as falhas quando acontecerem.

## Estrtégias

### Proteger e ser protegido
#### Serviço se auto protegendo
Precisamos fazer com que o sistema se auto preserve a fim de garantir ao máximo a "qualidade".
Com "qualidade", queremos dizer:
 - Algo bem feito
 - Algo que tem sempre o mesmo comportamento independente de fatores externos

Analogia cerveja:
 - Uma cerveja mesmo sendo muito gostosa, não tem "qualidade" se o gosto dela muda a cada gole.
 - Ou seja, além de ser bom, o comportamento deve ser uniforme.

Na ideia de microservices, o que buscamos é que o sistema mantenha o comportamento independente do ambiente. Por exemplo, queremos que ele responda da mesma maneira, não importa se temos 1 requisição por segundo ou 1 milhão.

Para atingir isso, precisamos cuidar da auto preservação.

Um exemplo disso é:
 - um sistema precisa responder em até 500ms
 - então vamos projetar o sistema para que responda nesse tempo, não importa se temos 1 requisição por segundo ou 1 milhão
 - para atingir isso, podemos por exemplo":
    - se o sistema só consegue responder 1 mil requisições por segundo, vamos barrar o restante para garantir o SLA de 500ms. Para as outras requisições, vamos pensar em outra estratégia.

#### Protegendo os outros serviços
Um serviço deve cuidar dos outros, não ser "egoísta", ajudando os outros serviços a se manterem de pé.
Fazemos isso não tentando chamar um serviço indefinidamente se está dando falhando. Devemos adotar estratégias para aguardar um pouco e esperar o serviço voltar ao ar.

Se um serviço está falhando, e um outro fica chamando ele, recebendo timeout e dando retry, basicamenteo o segundo sistema está "enterrando" o primeiro, "chutando cachorro morto".

> Um sistema lento no ar, pode ser pior do que um sistema fora do ar. Pois um sistema lento pode causar vários efeitos colaterais em outros serviços, deixando todo o sistema lento. Ou seja, um serviço retornar um 500 pode ser melhor do que um responder num tempo muito grande.

### Health check
É necessário termos uma forma de chamar um serviço pra saber se ele está "saudável".

Isso é diferente de só verificar se o sistema está "respondendo", ou seja, não é só verificar se o sistema tá de pé. É necessário que essa checagem verifique os componentes que o sistema depende, como banco de dados. 

#### Self healing
Um sistema que não está saudável, pode se recuperar se o tráfego parar ou diminuir temporariamente. Assim o sistema pode processar o que ficou emperrado, e voltar a ficar saudável quando terminar o processamento.

Veja que essa é uma estratégia melhor do que simplesmente matar o sistema e subir de novo, pois quando derrubamos o sistema pra subir de novo, nós perdemos as requisições que não foram processadas e vamos também perder as novas que chegaram no período em que o sistema estava subindo de novo.

Então, é interessante deixar o sistema apto a self healing a fim de não perder requisições.

#### Qualidade do health check
##### Health check passivo
É quando a checagem sabe a saúde somente quando alguém pergunta. Ou seja, o sistema pode estar morto, mas a checagem ainda não sabe. Ela só irá saber quando alguém perguntar.

##### Health check ativo
Quando o sistema fica se auto chamando, ou outro sistema exclusivo pra isso fica chamando o primeiro sistema, para verificar a saúde. Se verificar que não está ok, ele já pode chamar mecanismos de resiliência.

##### Nginx curiosidade
O free, tem healthcheck passivo. O pago, tem o ativo.

##### Probes do kubernetes
É uma ferramenta de health check ativo que o kubernetes fornece.

### Rate limiting
#### Proteção do sistema
Podemos limitar a quantidade de requisições que chegam no sistema para garantir a qualidade. Por exemplo, se o sistema só consegue garantir a qualidade quando está recebendo no máximo mil requisições por segundo, podemos limitar em mil por segundo, assim o sistema não recebe mais requisições do que ele consegue suportar.

#### Preferências por cliente
Em alguns casos, podemos ter um cliente do sistema que é muito mais importante que os outros. Nesse caso, pode não ser interessante esse cliente ter a mesma limitação que outros, que tem menor ou talvez nenhuma importancia.

Ex: 
 - Temos 10 clientes, e o sistema atende com qualidade somente 1k rps.
 - 1 desses clientes, representa 90% do faturamento.
 - Se aplicarmos o rate limiting padrão, e todos os clientes usam o sistema na mesma proporção, cada cliente conseguiria enviar 100 rps apenas.
 - Nesse caso, como um cliente é extremamente mais importante que os outros, pode ser interessante dar uma preferência à ele. E os clientes menos importante estão tendo uma preferência maior.

Pra resolver essa preferência podemos criar regras no rate limiting de acordo com o cliente.

Normalmente, isso é o correto a ser feito. Aplicar um rate limiting padrão sem essa personalização pode ser nada interessante.

Obs: veja que essa parte não envolve apenas tecnlogia, mas também a área de negócios pra entender qual estratégia adotar pra cada cliente.

### Circuit breaker
Uma maneira de proteger o sistema, fazendo com que as requisições que cheguem a ele sejam negadas.

Obs: circuit breaker é um "disjuntor".

circuito fechado = requisições chegam ao sistema
circuito aberto = requisições param de chegar
circuito meio aberto (half open) = permite uma quantidade limitada, pra verificar se o sistema tem condições de voltar à normalidade.

#### Decisões
Normalmente quem implementa isso é a pessoa que desenvolve. Isso demanda bastante tempo normalmente, e acaba ficando nelas a decisão de quantas requisições usar no half open, escolhem quando abrir ou fechar o circuito etc. O problema é que normalmente essa pessoa tem acesso à apenas um ou alguns microsserviços. Ou seja, essa pessoa talvez não tenha todo o contexto necessário pra tomar a melhor decisão.

Pra evitar que a pessoa que desenvolve precise tomar essas decisões, temos algumas ferramentas como o service mesh e API gateway, e então isso fica a cargo de pessoas com maior capacidade de tomar essas decisões.

### Api Gateway
É uma ferramenta para bloquear requisição indesejadas no sistema.

É a mesma analogia de um portão. Quando temos um portão, evitamos que as pessoas tenham acesso direto à porta da sua casa. Primeiro ela precisa passar por um portão, onde podemos ter um interfone, uma portaria etc, onde a pessoa precisará se apresentar primeiro. Assim, podemos tomar a decisão de se vamos atender a pessoa ou não, antes de ter ela na porta da sua casa.

#### Autenticação
Essa ferramenta é muito útil para autenticação, o que é muito útil no caso de microserviços pois assim, não precisamos que todos os microsserviços precisem ficar lidando com autenticação.

#### Outros recursos
O API gateway já pode ajudar na implementação de rate limiting e health checking, tirando do time de desenvolvimento a responsabilidade de ter que implementar isso na mão, o que já é uma grande vantagem.

#### Organização em contextos
Quando temos muitos serviços, as ordens de chamadas entre eles podem ficar extremamente complexos (ex: estrela da morte netflix). Essa organização é chamada de "coreografia".

Nesses cenários que começam a ficar caóticos, o API gateway pode ser útil pois ele ajuda a organizar os microserviços por contextos, criando um mapeamento com múltiplas API gateways.

Ex:
 - Temos um sistema de loja virtual
 - Parte do sistema é a parte de pagamentos, composta por 10 microserviços.
 - Em vez do restante do sistema, ter conhecimento de qual desses 10 microserviços chamar, ele chama um API gateway que contém o mapeamento para esses 10 microserviços.
 - Assim, o API gateway se comporta como um facade, e o restante do sistema apenas sabe que tem esse gateway, sem precisar saber dos detalhes dos microserviços que estão dentro dele.
 - Assim podemos ter vários API gateways dentro de um sistema, um para cada contexto, simplificando muito o sistema, pois os microserviços enxergam os "contextos" em vez de precisar saber qual e como chamar um microsserviço específico.

Essa organização facilita muita coisa, como documentação, desenvolvimento, facilidade de entendimento do sistema de maneira geral etc.

### Service mesh
Tipo de ferramenta muito usada nas empresas que possuem muitos microsserviços.

Ela permite um monitoramento de toda a rede, dando informações sobre chamadas que estão acontecendo entre os serviços.

Ele é um proxy, que todos os serviços chamariam a fim em vez de chamar um outro serviço diretamente.

Com essa centralização, conseguimos implementar mais facilmente coisas como:
 - mTLS (serviço A verifica se o serviço B é o B, e o B verifica se o A é A)
 - circuit breaker
 - retry
 - timeout
 - fault injection (testes de resiliência)
 - etc

Todas essas coisas não são triviais de se implementar, então ter uma ferramenta que facilita isso é muito bem vinda pois tira da equipe de desenvolvimento essa responsabilidade.

#### Providers
Alguns providers de service mesh sao:
 - istio
 - linkerd
 - consul connect
 - AWS App mesh

### Trabalhando de forma assíncrona
Para garantir a resiliência do sistema, devemos pensar todas as chamadas de maneira assíncrona.
Pra isso, em vez de chamar outros serviços de maneira direta, nós enviamos uma mensagem pra um broker (kafka, rabbitmq etc), e então o serviço desejado irá consumir a mensagem quando ele estiver disponível.

Isso traz a vantagem de evitar perda de dados, já que as mensagens ficam armazenadas até serem processadas, sem depender da disponibilidade imediata do sistema B.


#### Responsabilidade dos devs
Sobre esse ponto, é muito importante que os desenvolvedores entendam com profundidade como o broker/serviço de stream funciona. 

O que se tem muito hoje é o pessoal apenas usar um tutorial para aprender como emitir/consumir mensagens, sem profundidade. O problema é que a passagem de um parãmetro errado pode implicar em perda de dados, o que é um problema muito grande.

Então, por se tratar de algo bem crítico, nós devs devemos entender essas ferramentas com profundidade, pra não sermos um risco para o sistema.

### Retry
O retry é basicamente uma retentativa de chamada quando uma anterior não foi respondida.

#### Perigos
Numa arquitetura de microsserviços, um serviço pode ser chamado por vários outros. Se esse serviço passa por uma instabilidade, e todos os outros microsserviços ficam chamando e dando retry, esse serviço vai ter muita dificuldade pra voltar a ficar de pé, pois mesmo que ele consiga volta, vai ter sempre chamadas de retry pra resolver, assim não conseguindo processar as novas, que vão gerar novos retries. Ou seja, se um serviço fica recebendo retry na mesma taxa em que ele consegue processar as chamadas, teremos um ciclo que nunca vai terminar.

#### Evitando ciclo infinito de retries
Ao implementar retry, devemos faze-lo de uma maneira em que o intervalo entre os retries vai aumentando conforme a chamada não é bem sucedida. Assim, eventualmente a taxa de processamento das requisições será maior que a de retries e o serviço vai conseguir voltar à normalidade.

Importante dar atenção a isso, pois é muito comum o retry ser implementado na esperança de que ele por si só resolva algum problema. Mas na verdade não, se implementado de maneira incompatível com o sistema, em vez de ele resolver o problema vai estar só o prolongando.

#### Responsabilidade de devs/infra
Independente de quem implementa o retry, é importante que seja feito com esse intervalo de tempo que vai aumentando, do contrário vamos fazer com que o serviço nunca consiga voltar à normalidade.

É importante tocar nesse ponto pois normalmente isso não é implementado do zero mas sim usado alguma biblioteca, que por padrão, pode não vir configurado com esse intervanlo. Então devemos primeiro estudar como deve ser essas regras de retry, e independente de se usar uma biblioteca ou não, cuidar para que as regras sejam implementadas corretamente.

#### Backoff linear x Backoff exponencial
O linear é uma estratégia onde um intervalo de tempo entre os retries aumenta de maneira linear (ex: 1s, 2s, 3s).

Já o exponencial, é uma implementação em que intervalo de tempo aumenta exponencialmente.
Ex: 
 - 1 chamada falhou, a próxima acontece de novo em 2 segundos.
 - falhou, a próxima em 4
 - falhou, a próxima em 8
 - falhou, a próxima em 64

Assim, o tempo entre os retries vai aumentando bastante, dando folego pro serviço conseguir processar tudo o que ficou pendente.

Apesar de o exponencial ajudar, ainda pode não ser o suficiente, pois numa arquitetura de microsserviços, podemos ter vários que estão dando retry também, fazendo com que talvez ainda assim o serviço não consiga processar tudo. Pra isso temos uma outra estratégia que pode ser mais interessante, o Jitter backoff.

#### Jitter exponential backoff
É uma alteranativa para embaralhar o tempo das chamadas, evitando que chamadas cheguem ao mesmo tempo. 
Funciona assim:
 - basicamente é o exponencial
 - porém, a cada chamada, tem um tempo adicional randomico
 - assim, o intervalo entre as chamadas cresce de maneira exponencial, com um tempo a mais que dificilmetne outro serviço vai usar o mesmo
 - assim, é pouco provável que essa chamada chegue no serviço desejado ao mesmo tempo que outra

O jitter, por conta dessa probabilidade menor de as chamadas chegar ao mesmo tempo de outras, o intervalo entre as chamadas acaba diminuindo no frigir dos ovos, trazendo assim duas vantagens:
 - dá mais chacnes de o serviço voltar de pé
 - diminui o tempo em que o serviço fica engasgado tentando processar tudo

#### Referências
(Artigo AWS sobre backoff) https://aws.amazon.com/pt/blogs/architecture/exponential-backoff-and-jitter/
(Algoritmos de retry e lidando com os perigos) https://www.youtube.com/watch?v=1MkPpKPyBps

### Garantias de entrega
